{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from spacy.tokens import Token\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV,train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..//data//Womens Clothing E-Commerce Reviews Sentiment v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renames(feature, values):\n",
    "    Dict_cols={}\n",
    "    for value in values:\n",
    "        Dict_cols[value]=feature+value\n",
    "    return Dict_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding a categorical column\n",
    "column_name='Division Name'\n",
    "dummies= pd.get_dummies(df[column_name])\n",
    "df=pd.concat([df,dummies], axis=1,ignore_index=False)\n",
    "Division_columns=renames(column_name+'_',dummies.columns.tolist())\n",
    "df=df.rename(index=str, columns=Division_columns)\n",
    "\n",
    "column_name='Department Name'\n",
    "dummies= pd.get_dummies(df[column_name])\n",
    "df=pd.concat([df,dummies], axis=1,ignore_index=False)\n",
    "Department_columns=renames(column_name+'_',dummies.columns.tolist())\n",
    "df=df.rename(index=str, columns=Department_columns)\n",
    "\n",
    "column_name='Class Name'\n",
    "dummies= pd.get_dummies(df[column_name])\n",
    "df=pd.concat([df,dummies], axis=1,ignore_index=False)\n",
    "Class_columns=renames(column_name+'_',dummies.columns.tolist())\n",
    "df=df.rename(index=str, columns=Class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
       "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
       "       'Department Name', 'Class Name', 'processed_Review_text', 'PA_Polarity',\n",
       "       'PA_Subjectivity', 'Division Name_General',\n",
       "       'Division Name_General Petite', 'Division Name_Initmates',\n",
       "       'Department Name_Bottoms', 'Department Name_Dresses',\n",
       "       'Department Name_Intimate', 'Department Name_Jackets',\n",
       "       'Department Name_Tops', 'Department Name_Trend', 'Class Name_Blouses',\n",
       "       'Class Name_Casual bottoms', 'Class Name_Chemises',\n",
       "       'Class Name_Dresses', 'Class Name_Fine gauge', 'Class Name_Intimates',\n",
       "       'Class Name_Jackets', 'Class Name_Jeans', 'Class Name_Knits',\n",
       "       'Class Name_Layering', 'Class Name_Legwear', 'Class Name_Lounge',\n",
       "       'Class Name_Outerwear', 'Class Name_Pants', 'Class Name_Shorts',\n",
       "       'Class Name_Skirts', 'Class Name_Sleep', 'Class Name_Sweaters',\n",
       "       'Class Name_Swim', 'Class Name_Trend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discarding a empty reviews & removing the other columns\n",
    "\n",
    "df=df[((df.processed_Review_text.isna()==False) & (df.processed_Review_text.isnull()==False) & (df.processed_Review_text!=\"\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TF IDF Conversion\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2, 2), max_features=21448)\n",
    "# review_vectors = vectorizer.fit_transform(df[\"processed_Review_text\"])\n",
    "# features_df = pd.DataFrame(review_vectors.toarray(), columns = vectorizer.get_feature_names())\n",
    "# review_columns= vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TF IDF Conversion\n",
    "vectorizer = TfidfVectorizer()\n",
    "review_vectors = vectorizer.fit_transform(df[\"processed_Review_text\"])\n",
    "features_df = pd.DataFrame(review_vectors.toarray(), columns = vectorizer.get_feature_names())\n",
    "review_columns= vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df=pd.concat([df,features_df], axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordslist=df.columns.tolist()[42:]\n",
    "\n",
    "plt.subplots(figsize=(12,15))  \n",
    "i=1\n",
    "for (d,r),bucket in df.groupby(['Department Name','Recommended IND']):\n",
    "    \n",
    "    plt.subplot(6,2,i)\n",
    "    if r==0:\n",
    "        bucket[wordslist].sum().sort_values(ascending=False).head(10).plot(kind='bar',color='red')\n",
    "        plt.title(d+' Department - Not recommended')\n",
    "    else:\n",
    "        bucket[wordslist].sum().sort_values(ascending=False).head(10).plot(kind='bar',color='green')\n",
    "        plt.title(d+' Department - Recommended')\n",
    "    plt.xticks(rotation=60)\n",
    "    \n",
    "    i=i+1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Clothing ID','Title','Division Name', 'Department Name', 'Class Name','Positive Feedback Count','Review Text','processed_Review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFeature=df.columns.tolist()\n",
    "OutputFeature='Recommended IND'\n",
    "InputFeature.remove(OutputFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datetime_start=datetime.datetime.now()\n",
    "print(str(datetime_start)+\" : PCA model building started\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_InputFeature_std = scaler.fit_transform(df[InputFeature])\n",
    "df_pca = IncrementalPCA(n_components=8000, batch_size=10000).fit(df_InputFeature_std)\n",
    "\n",
    "datetime_completed=datetime.datetime.now()\n",
    "minutes_diff = round((datetime_completed - datetime_start).total_seconds() / 60.0,2)\n",
    "\n",
    "print(str(datetime_completed)+\" : PCA model completed in \"+str(minutes_diff)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_pd=pd.DataFrame(df_pca.components_)\n",
    "PCA_InputFeature=df_pca_pd.columns.tolist()\n",
    "df_pca_pd[OutputFeature]=df[OutputFeature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "x_values = range(1, df_pca.n_components_+1)\n",
    "ax.plot(x_values, df_pca.explained_variance_ratio_, lw=2, label='explained variance')\n",
    "ax.plot(x_values, np.cumsum(df_pca.explained_variance_ratio_), lw=2, label='cumulative explained variance')\n",
    "ax.set_title('explained variance of components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datetime_start=datetime.datetime.now()\n",
    "# print(str(datetime_start)+\" : LDA model building started\")\n",
    "\n",
    "# lda = LinearDiscriminantAnalysis(n_components=2000)\n",
    "# df_lda = lda.fit(df[InputFeature], df[OutputFeature]).transform(df[InputFeature])\n",
    "\n",
    "# datetime_completed=datetime.datetime.now()\n",
    "# minutes_diff = round((datetime_completed - datetime_start).total_seconds() / 60.0,2)\n",
    "\n",
    "# print(str(datetime_completed)+\" : LDA model completed in \"+str(minutes_diff)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Hyper parameter selection used Grid Search\n",
    "\n",
    "def param_selection(model,param_grid,InputFeatureData,OutputFeatureData, nfolds=3):\n",
    "#     print(str(datetime.datetime.now())+\" : Starting Param selection\")\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=nfolds,verbose =1)\n",
    "    grid_search.fit(InputFeatureData,OutputFeatureData)\n",
    "    print(\"Best Parmater for model : \"+ str(grid_search.best_params_))\n",
    "#     print(str(datetime.datetime.now())+\" : Param selection is completed\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def Category_coefs(modelbest_estimator,columnslist, ImpFtrShow, label, subplotnbr, InputFeature=InputFeature):\n",
    "        \n",
    "    if type(modelbest_estimator).__name__=='LogisticRegression':\n",
    "        if(subplotnbr>0):\n",
    "            plt.subplot(2,2,subplotnbr);\n",
    "        \n",
    "        # Coeffiencents\n",
    "        coefs=pd.DataFrame({'Featrures':InputFeature, 'Coeff':modelbest_estimator.coef_[0]})\n",
    "        coefs=coefs[coefs['Featrures'].isin(columnslist)]\n",
    "        if ImpFtrShow==0 or ImpFtrShow*2>len(coefs['Featrures']) :\n",
    "            coefs=coefs.sort_values(by=['Coeff'],ascending=False)\n",
    "            title= label+' Features of Coeff''s '\n",
    "        else:\n",
    "            ## Accounting both positive & negative important coefficients\n",
    "            coefs=pd.concat([coefs.sort_values(by=['Coeff'],ascending=False).head(ImpFtrShow),coefs.sort_values(by=['Coeff'],ascending=True).tail(ImpFtrShow)])\n",
    "            title='Top & Bottom '+str(ImpFtrShow*2)+' '+label+' Features of Coeff''s '\n",
    "        plt.bar(coefs['Featrures'], coefs['Coeff']);\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=70)\n",
    "    \n",
    "    elif type(modelbest_estimator).__name__=='MultinomialNB':\n",
    "        \n",
    "        # feature_log_prob_\n",
    "        pred1=pd.DataFrame({'Featrures':InputFeature, 'prob':modelbest_estimator.feature_log_prob_[1]})\n",
    "        pred0=pd.DataFrame({'Featrures':InputFeature, 'prob':modelbest_estimator.feature_log_prob_[0]})\n",
    "        \n",
    "        pred0=pred0[pred0['Featrures'].isin(columnslist)]\n",
    "        pred1=pred1[pred1['Featrures'].isin(columnslist)]\n",
    "        \n",
    "        if ImpFtrShow==0 or ImpFtrShow*2>len(pred0['Featrures'])  :\n",
    "            pred0=pred0.sort_values(by=['prob'],ascending=False)\n",
    "            pred1=pred1.sort_values(by=['prob'],ascending=False)\n",
    "            title= label+' Features of log probablity '\n",
    "        else:\n",
    "            pred0=pred0.sort_values(by=['prob'],ascending=False).head(ImpFtrShow)\n",
    "            pred1=pred1.sort_values(by=['prob'],ascending=False).head(ImpFtrShow)\n",
    "            title='Top '+str(ImpFtrShow)+' '+label+' Features of log probablity'\n",
    "        \n",
    "        if(subplotnbr==0):\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.bar(pred0['Featrures'], pred0['prob'], color='red');\n",
    "            plt.title(title+ ' for NonRec')\n",
    "            plt.xticks(rotation=70)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.bar(pred1['Featrures'], pred1['prob'], color='green');\n",
    "            plt.title(title+ ' for Rec')\n",
    "            plt.xticks(rotation=70)\n",
    "        else:\n",
    "            plt.subplot(4,4,(subplotnbr*2)-1)\n",
    "            plt.bar(pred0['Featrures'], pred0['prob'], color='red');\n",
    "            plt.title(title)\n",
    "            plt.xticks(rotation=70)\n",
    "            plt.subplot(4,4,(subplotnbr*2))\n",
    "            plt.bar(pred1['Featrures'], pred1['prob'], color='green');\n",
    "#             plt.title(title+ ' for Rec')\n",
    "            plt.xticks(rotation=70)\n",
    "    \n",
    "    elif type(modelbest_estimator).__name__=='RandomForestClassifier':\n",
    "        if(subplotnbr>0):\n",
    "            plt.subplot(2,2,subplotnbr);\n",
    "        \n",
    "        # Important Features\n",
    "        coefs=pd.DataFrame({'Featrures':InputFeature, 'Coeff':modelbest_estimator.feature_importances_})\n",
    "        coefs=coefs[coefs['Featrures'].isin(columnslist)]\n",
    "        if ImpFtrShow==0 or ImpFtrShow*2>len(coefs['Featrures']) :\n",
    "            coefs=coefs.sort_values(by=['Coeff'],ascending=False)\n",
    "            title= label+' Important Features '\n",
    "        else:\n",
    "            coefs=coefs.sort_values(by=['Coeff'],ascending=False).head(ImpFtrShow*2)\n",
    "            title='Top  '+str(ImpFtrShow*2)+' '+label+' Important Features '\n",
    "        plt.bar(coefs['Featrures'], coefs['Coeff']);\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=70)\n",
    "        \n",
    "# helper to plot ROC curves\n",
    "def plot_roc_curves(fprs, tprs, names=[]):    \n",
    "    \n",
    "    i=0\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        if len(names)==0:\n",
    "            plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % metrics.auc(fpr, tpr))\n",
    "        else:\n",
    "            plt.plot(fpr, tpr, label=names[i]+' (AUC = %0.2f)' % metrics.auc(fpr, tpr))\n",
    "        i=i+1\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "#     plt.show()\n",
    "\n",
    "def validation(modelbest_estimator,InputFeatureData,OutputFeatureData, X_train, X_test, y_train, y_test, datetime_modelfit,nfolds):\n",
    "    print(\" \")\n",
    "    print(\"********** Validation *************\")\n",
    "    \n",
    "    plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    if len(X_train)==0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(InputFeatureData,OutputFeatureData,  test_size=0.2, random_state=0)\n",
    "\n",
    "    y_pred = modelbest_estimator.predict(X_test)\n",
    "    \n",
    "    ## Confusion Matrix \n",
    "    plt.subplot(2,2,1)\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d',xticklabels=['No','Yes'], yticklabels=['No','Yes'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "#     plt.show()\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    plot_roc_curves([fpr], [tpr])\n",
    "\n",
    "    if nfolds<=1 :\n",
    "        ## Holdout validation\n",
    "        print('Accuracy Score : '+str(metrics.accuracy_score(y_test,y_pred )))\n",
    "        print('precision  : '+str(metrics.precision_score(y_test,y_pred ))) \n",
    "        print('recall  : '+str(metrics.recall_score(y_test,y_pred ))) \n",
    "        print('AUC  : '+str(metrics.roc_auc_score(y_test, y_pred)))\n",
    "    else:\n",
    "        ## Cross fold Validation \n",
    "        \n",
    "        scores=cross_val_score(modelbest_estimator, InputFeatureData,OutputFeatureData, cv=nfolds, scoring=\"accuracy\")\n",
    "        plt.subplot(2,2,3)\n",
    "        pd.Series(scores).plot(kind=\"box\", label=\"Accuracy\");\n",
    "        plt.title('RMSE from '+str(nfolds)+' Folds (Accuracy)')\n",
    "\n",
    "        print(\"Cross Validation Accuracy Scores \"+str(scores))\n",
    "        print(\"Cross Validation Accuracy Mean Score \"+str(np.mean(scores, dtype=np.float64)))\n",
    "        \n",
    "        scores=cross_val_score(modelbest_estimator,InputFeatureData,OutputFeatureData, cv=nfolds, scoring=\"precision\")\n",
    "        print(\"Cross Validation Accuracy precision Score \"+str(np.mean(scores, dtype=np.float64)))\n",
    "        plt.subplot(2,2,4)\n",
    "        pd.Series(scores).plot(kind=\"box\", label=\"precision\");\n",
    "        plt.title('RMSE from '+str(nfolds)+' Folds (precision)')\n",
    "\n",
    "        datetime_cv=datetime.datetime.now()\n",
    "        minutes_diff = round((datetime_cv - datetime_modelfit).total_seconds() / 60.0,2)\n",
    "        print(\"Model Cross Validation completed in \"+ str(minutes_diff) + \" minutes \")\n",
    "    plt.tight_layout()\n",
    "    print(\" \")\n",
    "\n",
    "def model_experiment(model,param_grid,df, InputFeaturecols,OutputFeaturecols, nfolds=[3,3], ImpFtrShow=10, Reviewonly=False, FeatureReduction=\"None\"):\n",
    "    ## Parameters ##\n",
    "    ## model - Input model\n",
    "    ## param_grid - model parameters in dict type to find best one, if no need to find - pass empty dict value\n",
    "    ## nfolds - 1st value :GridSearchCV nfold value, 2nd value - Cross Validation nfold value. if you want to proceed with holdout validation, pass 0 in 2nd parameter\n",
    "    ## ImpFtrShow - Number of attribute to show\n",
    "    \n",
    "    print(str(datetime.datetime.now())+\" : Starting the model experiments\")\n",
    "    print(\" \")    \n",
    "    \n",
    "    print(\"*******\", type(model).__name__,\"*****\")\n",
    "    print(\"Number Input Features : \"+ str(len(InputFeaturecols)))\n",
    "    if len(param_grid)>0:\n",
    "        print(\"Grid Input : \"+ str(param_grid))\n",
    "        print(\"Grid Search CV : \"+ str(nfolds[0]))\n",
    "    if nfolds[1]<2:\n",
    "        print(\"Validation type : HoldOut\")\n",
    "    else:\n",
    "        print(\"Validation type : Cross Fold Validation\")\n",
    "        print(\"Cross Fold Split Size : \"+ str(nfolds[1]))\n",
    "    print(\"Important Feature Filter : \"+ str(ImpFtrShow))\n",
    "    print(\"Feature Reduction : \"+FeatureReduction)\n",
    "    print(\"Show Category wise important Feature : False\" if Reviewonly else \"Show Category wise important Feature : True\" )\n",
    "    print(\"***********************\")\n",
    "    print(\" \")\n",
    "\n",
    "    InputFeatureData=df[InputFeaturecols]\n",
    "    OutputFeatureData=df[OutputFeaturecols]\n",
    "    \n",
    "    if 'PA_Polarity' in InputFeaturecols:\n",
    "        InputFeatureData['PA_Polarity'] = (InputFeatureData['PA_Polarity'] +1 )/2\n",
    "    \n",
    "    datetime_start=datetime.datetime.now()\n",
    "    \n",
    "    if len(param_grid)==0:\n",
    "        ## Spliting the train & test data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(InputFeatureData,OutputFeatureData,  test_size=0.2, random_state=0)\n",
    "        \n",
    "        # Fitting a model based on given parameter\n",
    "        modelbest_estimator=model\n",
    "        modelbest_estimator.fit(X_train,y_train)\n",
    "        \n",
    "        datetime_modelfit=datetime.datetime.now()\n",
    "        minutes_diff = round((datetime_modelfit - datetime_start).total_seconds() / 60.0,2)\n",
    "        print(\"Model Fit completed in \"+ str(minutes_diff) + \" minutes \")\n",
    "        validation(modelbest_estimator,InputFeatureData,OutputFeatureData, X_train, X_test, y_train, y_test,datetime_modelfit, nfolds[1])\n",
    "    \n",
    "    else:\n",
    "        ## Experimenting model with different parameters\n",
    "        modelbest_estimator=param_selection(model,param_grid,InputFeatureData,OutputFeatureData,nfolds[0])\n",
    "        \n",
    "        datetime_modelfit=datetime.datetime.now()\n",
    "        minutes_diff = round((datetime_modelfit - datetime_start).total_seconds() / 60.0,2)\n",
    "        print(\"Model GridSearch CV completed in \"+ str(minutes_diff) + \" minutes \")\n",
    "        \n",
    "        validation(modelbest_estimator,InputFeatureData,OutputFeatureData, [],[],[],[],datetime_modelfit, nfolds[1])\n",
    "  \n",
    "    if type(model).__name__ in ('LogisticRegression','MultinomialNB','RandomForestClassifier') and FeatureReduction==\"None\":\n",
    "        \n",
    "        # Important Features for all\n",
    "        plt.subplots(figsize=(12,4))\n",
    "        Category_coefs(modelbest_estimator,InputFeaturecols,ImpFtrShow*2,'All',0,InputFeaturecols)\n",
    "        plt.tight_layout()\n",
    "      \n",
    "        if(Reviewonly==False):\n",
    "            if type(model).__name__=='MultinomialNB':\n",
    "                plt.subplots(figsize=(15,15))   \n",
    "            else:\n",
    "                plt.subplots(figsize=(12,8))\n",
    "\n",
    "            # Important Features for each catefory\n",
    "            Category_coefs(modelbest_estimator,list(Division_columns.values()),ImpFtrShow,'Division',1)\n",
    "            Category_coefs(modelbest_estimator,list(Department_columns.values()),ImpFtrShow,'Department',2)\n",
    "            Category_coefs(modelbest_estimator,list(Class_columns.values()),ImpFtrShow,'Class',3)\n",
    "            Category_coefs(modelbest_estimator,review_columns,ImpFtrShow, 'Reviews',4)\n",
    "            plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=linear_model.LogisticRegression(n_jobs=1, solver='liblinear', C=1, penalty='l2', max_iter=1000)\n",
    "param_grid={}#{'C':[0.01,1,100,1000]} \n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,3], ImpFtrShow=10, Reviewonly=False,FeatureReduction=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=linear_model.LogisticRegression(n_jobs=1, solver='liblinear', C=1, penalty='l2', max_iter=1000)\n",
    "param_grid={}#{'C':[0.01,1,100,1000]} \n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature[33:],OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=linear_model.LogisticRegression(n_jobs=1, solver='liblinear', C=0.01, penalty='l2', max_iter=1000)\n",
    "param_grid={'C':[0.01,1,100,1000]} \n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df_pca_pd, InputFeaturecols=PCA_InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "param_grid={}#{'alpha':np.linspace(0.1,1,5)} \n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=5, Reviewonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.1)\n",
    "param_grid={'alpha':np.linspace(0.1,1,5)} \n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature[33:],OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=5, Reviewonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_pca_pd_minmaxscale=pd.DataFrame(scaler.fit_transform(df_pca_pd[PCA_InputFeature]))\n",
    "df_pca_pd_minmaxscale[OutputFeature]=df_pca_pd[OutputFeature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.1)\n",
    "param_grid={'alpha':np.linspace(0.1,1,5)} \n",
    "model_experiment(model=model,param_grid=param_grid,df=df_pca_pd_minmaxscale, InputFeaturecols=PCA_InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,max_depth=None,n_jobs=-1)\n",
    "param_grid={}\n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=5, Reviewonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature[33:],OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df_pca_pd_minmaxscale, InputFeaturecols=PCA_InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "param_grid={'n_neighbors':np.linspace(3,12,4)} \n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,1], ImpFtrShow=5, Reviewonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature[33:],OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df_pca_pd_minmaxscale, InputFeaturecols=PCA_InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(C=10,  gamma=0.1)\n",
    "param_grid={}\n",
    "\n",
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,0], ImpFtrShow=10, Reviewonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df, InputFeaturecols=InputFeature[33:],OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiment(model=model,param_grid=param_grid,df=df_pca_pd_minmaxscale, InputFeaturecols=PCA_InputFeature,OutputFeaturecols=OutputFeature, nfolds=[2,5], ImpFtrShow=10, Reviewonly=True,FeatureReduction=\"PCA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
